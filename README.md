# Advanced Training Algorithms for Deep Neural Networks

–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –æ–±—É—á–µ–Ω–∏—è –≥–ª—É–±–æ–∫–∏—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –≤ —Ä–∞–º–∫–∞—Ö –∫—É—Ä—Å–æ–≤–æ–π —Ä–∞–±–æ—Ç—ã.

## üìã –û–±–∑–æ—Ä

–î–∞–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –ø—è—Ç–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π:

1. **FER (Reducing Flipping Errors)** - —É–º–µ–Ω—å—à–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
2. **Gradient Correction** - –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏  
3. **Forward Signal Propagation** - –æ–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤
4. **Selective Localized Learning** - —Å–µ–ª–µ–∫—Ç–∏–≤–Ω–æ–µ –ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
5. **Zero-Shot Hyperparameter Transfer** - –ø–µ—Ä–µ–Ω–æ—Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è

–í—Å–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å API PyTorch –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–æ–µ–∫—Ç—ã.

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install torch torchvision numpy matplotlib seaborn pandas tqdm
```

### –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from advanced_optimizers import FEROptimizer
import torch
import torch.nn as nn

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
model = nn.Sequential(
    nn.Linear(784, 512),
    nn.ReLU(), 
    nn.Linear(512, 10)
)

# –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ FER
optimizer = FEROptimizer(
    model.parameters(),
    base_optimizer=torch.optim.Adam,
    base_optimizer_kwargs={'lr': 0.001},
    fer_weight=0.1
)

# –û–±—ã—á–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
for epoch in range(num_epochs):
    for batch in dataloader:
        optimizer.zero_grad()
        loss = criterion(model(batch.x), batch.y)
        loss.backward()
        optimizer.step()
```

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
‚îú‚îÄ‚îÄ advanced_optimizers/           # –û—Å–Ω–æ–≤–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–∫–µ—Ç–∞
‚îÇ   ‚îú‚îÄ‚îÄ fer_optimizer.py          # FER –∞–ª–≥–æ—Ä–∏—Ç–º
‚îÇ   ‚îú‚îÄ‚îÄ gradient_correction.py    # Gradient Correction
‚îÇ   ‚îú‚îÄ‚îÄ forward_signal.py         # Forward Signal Propagation  
‚îÇ   ‚îú‚îÄ‚îÄ localized_learning.py     # Localized Learning
‚îÇ   ‚îî‚îÄ‚îÄ zero_shot_transfer.py     # Zero-Shot Transfer
‚îú‚îÄ‚îÄ experiments_comparison.ipynb   # Jupyter notebook —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º–∏
‚îú‚îÄ‚îÄ coursework_report.md          # –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫—É—Ä—Å–æ–≤–æ–π —Ä–∞–±–æ—Ç–µ
‚îú‚îÄ‚îÄ Advanced-training-algorithms.pdf  # –ò—Å—Ö–æ–¥–Ω–∞—è —Å—Ç–∞—Ç—å—è —Å –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏
‚îú‚îÄ‚îÄ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è_–∫_–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è.txt   # –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫—É—Ä—Å–æ–≤–æ–π —Ä–∞–±–æ—Ç–µ
‚îî‚îÄ‚îÄ README.md                     # –≠—Ç–æ—Ç —Ñ–∞–π–ª
```

## üî¨ –û–ø–∏—Å–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤

### 1. FER (Reducing Flipping Errors)

–ê–ª–≥–æ—Ä–∏—Ç–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ —É–º–µ–Ω—å—à–µ–Ω–∏–µ "–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–π" –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–∞—Ö –ø—É—Ç–µ–º —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤.

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- –ü–∞–º—è—Ç—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
- –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
- –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```python
from advanced_optimizers import create_fer_optimizer

optimizer = create_fer_optimizer(
    model.parameters(),
    lr=0.001,
    fer_weight=0.1,
    consistency_threshold=0.9
)
```

### 2. Gradient Correction

–§—Ä–µ–π–º–≤–æ—Ä–∫ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –º–æ–¥—É–ª–∏ GC-W –∏ GC-ODE –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- –ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
- –û–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
- –°–æ–∫—Ä–∞—â–µ–Ω–∏–µ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è –Ω–∞ ~20%

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```python
from advanced_optimizers import create_gradient_correction_optimizer

optimizer = create_gradient_correction_optimizer(
    model.parameters(),
    lr=0.001,
    use_gcw=True,
    use_gcode=True,
    device=device
)
```

### 3. Forward Signal Propagation

–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –æ–±—Ä–∞—Ç–Ω–æ–º—É —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–∞—é—â–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤.

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- –ë–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å–ª–æ–µ–≤
- –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ SigProp —Å–ª–æ–∏

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```python
from advanced_optimizers import SigPropNet, create_sigprop_optimizer

model = SigPropNet(input_dim=784, hidden_dims=[512, 256], output_dim=10)
optimizer = create_sigprop_optimizer(model, lr=0.001, signal_lr=0.0001)
```

### 4. Selective Localized Learning

–ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ (–•–µ–±–±–æ–≤—Å–∫–æ–µ) –æ–±—É—á–µ–Ω–∏–µ —Å SGD, —Å–µ–ª–µ–∫—Ç–∏–≤–Ω–æ –≤—ã–±–∏—Ä–∞—è —Å–ª–æ–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π.

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- –£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è –≤ 1.5 —Ä–∞–∑–∞
- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ –æ–±—É—á–µ–Ω–∏—è
- –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```python
from advanced_optimizers import create_localized_optimizer

optimizer = create_localized_optimizer(
    model,
    lr=0.001,
    hebbian_lr=0.0001,
    selection_mode='dynamic'
)
```

### 5. Zero-Shot Hyperparameter Transfer

ŒºTransfer –¥–ª—è –ø–µ—Ä–µ–Ω–æ—Å–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –º–∞–ª—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –±–æ–ª—å—à–∏–µ –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- Maximal Update Parametrization (ŒºP)
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ learning rate
- –†–∞–¥–∏–∫–∞–ª—å–Ω–æ–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ –∑–∞—Ç—Ä–∞—Ç –Ω–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫—É

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```python
from advanced_optimizers import create_mu_transfer_optimizer

optimizer = create_mu_transfer_optimizer(
    large_model,
    base_model_config={'width': 64, 'depth': 4},
    target_model_config={'width': 512, 'depth': 12},
    base_hyperparams={'lr': 0.001, 'weight_decay': 0.01}
)
```

## üß™ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã

–î–ª—è –∑–∞–ø—É—Å–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –æ—Ç–∫—Ä–æ–π—Ç–µ `experiments_comparison.ipynb` –≤ Jupyter Notebook:

```bash
jupyter notebook experiments_comparison.ipynb
```

Notebook —Å–æ–¥–µ—Ä–∂–∏—Ç:
- –ó–∞–≥—Ä—É–∑–∫—É –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö (MNIST, CIFAR-10)
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (–ø—Ä–∏–º–µ—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)

| –ê–ª–≥–æ—Ä–∏—Ç–º | MNIST –¢–æ—á–Ω–æ—Å—Ç—å | CIFAR-10 –¢–æ—á–Ω–æ—Å—Ç—å | –í—Ä–µ–º—è/—ç–ø–æ—Ö–∞ |
|----------|---------------|------------------|-------------|
| SGD | 95.2% | 68.4% | 12.3s |
| Adam | 96.8% | 71.2% | 13.1s |
| **FER** | **97.1%** | **72.1%** | 13.8s |
| GradCorr | 96.9% | 71.8% | 14.2s |
| LocalLearning | 96.3% | 70.5% | **11.7s** |

### –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã

‚úÖ **FER** –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª—É—á—à—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±–æ–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö  
‚úÖ **Localized Learning** –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –Ω–∞–∏–±–æ–ª—å—à—É—é —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è  
‚úÖ **Gradient Correction** –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ  
‚úÖ –í—Å–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—Ç –±–∞–∑–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã (SGD, Adam)

## üìñ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

### API Reference

–ö–∞–∂–¥—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å–ª–µ–¥—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É API PyTorch:

```python
class AdvancedOptimizer(torch.optim.Optimizer):
    def __init__(self, params, **kwargs): ...
    def step(self, closure=None): ...
    def zero_grad(self): ...
    def state_dict(self): ...
    def load_state_dict(self, state_dict): ...
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

#### FER Optimizer
- `fer_weight` (float): –í–µ—Å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ FER (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.1)
- `consistency_threshold` (float): –ü–æ—Ä–æ–≥ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.9)
- `memory_size` (int): –†–∞–∑–º–µ—Ä –±—É—Ñ–µ—Ä–∞ –ø–∞–º—è—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1000)

#### Gradient Correction
- `use_gcw` (bool): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GC-W –º–æ–¥—É–ª—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: True)
- `use_gcode` (bool): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GC-ODE –º–æ–¥—É–ª—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: True)
- `gcw_strength` (float): –°–∏–ª–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ GC-W (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.1)

#### Localized Learning
- `hebbian_lr` (float): Learning rate –¥–ª—è –•–µ–±–±–æ–≤—Å–∫–∏—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.001)
- `selection_mode` (str): –†–µ–∂–∏–º –≤—ã–±–æ—Ä–∞ —Å–ª–æ–µ–≤ ('static' –∏–ª–∏ 'dynamic')
- `weak_supervision_weight` (float): –í–µ—Å —Å–ª–∞–±–æ–≥–æ –Ω–∞–¥–∑–æ—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.1)

## üõ†Ô∏è –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–∏—Å—Ç–µ–º–µ

- Python 3.7+
- PyTorch 1.9+
- NumPy
- Matplotlib (–¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏)
- Jupyter Notebook (–¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤)

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

```bash
git clone <repository_url>
cd advanced-training-algorithms
pip install -e .
```

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
python -m pytest tests/
```

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞

1. –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π —Ñ–∞–π–ª –≤ `advanced_optimizers/`
2. –ù–∞—Å–ª–µ–¥—É–π—Ç–µ—Å—å –æ—Ç `torch.optim.Optimizer`
3. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –º–µ—Ç–æ–¥—ã `step()`, `zero_grad()`, `state_dict()`, `load_state_dict()`
4. –î–æ–±–∞–≤—å—Ç–µ –∏–º–ø–æ—Ä—Ç –≤ `__init__.py`
5. –°–æ–∑–¥–∞–π—Ç–µ convenience —Ñ—É–Ω–∫—Ü–∏—é `create_*_optimizer()`

## üìö –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã

### –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏

**FER —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è:**
```
L_FER = L_standard + Œª_FER * R_consistency
```

**Gradient Correction:**
```
g_corrected = g_original + Œ±*GC_W(g) + Œ≤*GC_ODE(g)
```

**ŒºTransfer scaling:**
```
lr_layer = lr_base * scaling_factor(layer_type, width_ratio)
```

–ü–æ–¥—Ä–æ–±–Ω—ã–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≤—ã–≤–æ–¥—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ –æ—Ç—á–µ—Ç–µ `coursework_report.md`.

## ü§ù –í–∫–ª–∞–¥ –≤ –ø—Ä–æ–µ–∫—Ç

–ú—ã –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤—É–µ–º –≤–∫–ª–∞–¥ –≤ —Ä–∞–∑–≤–∏—Ç–∏–µ –ø—Ä–æ–µ–∫—Ç–∞! –ü–æ–∂–∞–ª—É–π—Å—Ç–∞:

1. –§–æ—Ä–∫–Ω–∏—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
2. –°–æ–∑–¥–∞–π—Ç–µ feature branch (`git checkout -b feature/amazing-feature`)
3. –ö–æ–º–º–∏—Ç—å—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è (`git commit -m 'Add amazing feature'`)
4. –ü—É—à—å—Ç–µ –≤ branch (`git push origin feature/amazing-feature`)
5. –û—Ç–∫—Ä–æ–π—Ç–µ Pull Request

### –û–±–ª–∞—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è

- [ ] –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- [ ] –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
- [ ] –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- [ ] –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ø–æ–ø—É–ª—è—Ä–Ω—ã–º–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏ (Hugging Face, timm)

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

–î–∞–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –≤ —Ä–∞–º–∫–∞—Ö –∫—É—Ä—Å–æ–≤–æ–π —Ä–∞–±–æ—Ç—ã –∏ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–ª–µ–π.

## üìû –ö–æ–Ω—Ç–∞–∫—Ç—ã

- **–ê–≤—Ç–æ—Ä:** [–í–∞—à–µ –∏–º—è]
- **Email:** [–≤–∞—à email]
- **–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç:** [–Ω–∞–∑–≤–∞–Ω–∏–µ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞]
- **–ö—É—Ä—Å:** [–∫—É—Ä—Å –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å]

## üôè –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏

- PyTorch –∫–æ–º–∞–Ω–¥–µ –∑–∞ –æ—Ç–ª–∏—á–Ω—ã–π —Ñ—Ä–µ–π–º–≤–æ—Ä–∫
- –ê–≤—Ç–æ—Ä–∞–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –ø–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º –æ–±—É—á–µ–Ω–∏—è
- –ù–∞—É—á–Ω–æ–º—É —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—é –∑–∞ —Ü–µ–Ω–Ω—ã–µ —Å–æ–≤–µ—Ç—ã –∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É

---

*–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç —è–≤–ª—è–µ—Ç—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç–æ–∫ –≤ –æ–±–ª–∞—Å—Ç–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.*